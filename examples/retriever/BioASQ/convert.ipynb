{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='9b'\n",
    "reqa_json=f'../../../data/BioASQ/{dataset}/train.json'\n",
    "reqa_test_json=f'../../../data/BioASQ/{dataset}/test.json'\n",
    "output_dir=f'../../../data/bioasq_formatted/{dataset}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['questions', 'answers', 'question_ids'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(reqa_json) as f:\n",
    "    data=json.load(f)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data:\n",
    "    for i in range(len(data[key])):\n",
    "        if isinstance(data[key][i],str):\n",
    "            data[key][i]=data[key][i].replace('\\r','').replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of q-a pairs: 5828\n",
      "size of unique answers: 5786\n",
      "size of unique questions: 3740\n"
     ]
    }
   ],
   "source": [
    "print('size of q-a pairs:',len(data['questions']))\n",
    "print(f'size of unique answers:',len(set(data['answers'])))\n",
    "print(f'size of unique questions:',len(set(data['questions'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 4662 dev size 1166\n",
      "[fold: 1][train] size of unique answers: 4626\n",
      "[fold: 1][train] size of unique questions: 3166\n",
      "[fold: 1][train] size of q-a pairs: 4662\n",
      "[fold: 1][dev] size of unique answers: 1164\n",
      "[fold: 1][dev] size of unique questions: 1007\n",
      "[fold: 1][dev] size of q-a pairs: 1166\n",
      "train size 4662 dev size 1166\n",
      "[fold: 2][train] size of unique answers: 4628\n",
      "[fold: 2][train] size of unique questions: 3148\n",
      "[fold: 2][train] size of q-a pairs: 4662\n",
      "[fold: 2][dev] size of unique answers: 1162\n",
      "[fold: 2][dev] size of unique questions: 1001\n",
      "[fold: 2][dev] size of q-a pairs: 1166\n",
      "train size 4662 dev size 1166\n",
      "[fold: 3][train] size of unique answers: 4635\n",
      "[fold: 3][train] size of unique questions: 3153\n",
      "[fold: 3][train] size of q-a pairs: 4662\n",
      "[fold: 3][dev] size of unique answers: 1158\n",
      "[fold: 3][dev] size of unique questions: 1005\n",
      "[fold: 3][dev] size of q-a pairs: 1166\n",
      "train size 4663 dev size 1165\n",
      "[fold: 4][train] size of unique answers: 4636\n",
      "[fold: 4][train] size of unique questions: 3134\n",
      "[fold: 4][train] size of q-a pairs: 4663\n",
      "[fold: 4][dev] size of unique answers: 1155\n",
      "[fold: 4][dev] size of unique questions: 1010\n",
      "[fold: 4][dev] size of q-a pairs: 1165\n",
      "train size 4663 dev size 1165\n",
      "[fold: 5][train] size of unique answers: 4628\n",
      "[fold: 5][train] size of unique questions: 3145\n",
      "[fold: 5][train] size of q-a pairs: 4663\n",
      "[fold: 5][dev] size of unique answers: 1163\n",
      "[fold: 5][dev] size of unique questions: 1024\n",
      "[fold: 5][dev] size of q-a pairs: 1165\n"
     ]
    }
   ],
   "source": [
    "set_seed(SEED)\n",
    "kf = KFold(n_splits=5)\n",
    "data_arr = list(zip(data['questions'], data['answers']))\n",
    "random.shuffle(data_arr)\n",
    "fold = 1\n",
    "for train_ids, dev_ids in kf.split(data_arr):\n",
    "    train = [data_arr[i] for i in train_ids]\n",
    "    dev = [data_arr[i] for i in dev_ids]\n",
    "    print('train size', len(train), 'dev size', len(dev))\n",
    "    train = {\n",
    "        'questions': [x[0] for x in train],\n",
    "        'answers': [x[1] for x in train],\n",
    "    }\n",
    "    dev = {\n",
    "        'questions': [x[0] for x in dev],\n",
    "        'answers': [x[1] for x in dev],\n",
    "    }\n",
    "    conf = {'train': train, 'dev': dev}\n",
    "    \n",
    "    fold_output_dir = os.path.join(output_dir, f'fold_{fold}')\n",
    "    os.makedirs(fold_output_dir, exist_ok=True)\n",
    "    for name, data in conf.items():\n",
    "        # 处理答案\n",
    "        answer_dict = {}\n",
    "        unique_answers = []\n",
    "        with open(os.path.join(fold_output_dir, f'{name}_corpus.tsv'),\n",
    "                  'w') as f:\n",
    "            # 答案语料\n",
    "            for answer in data['answers']:\n",
    "                if answer in answer_dict:\n",
    "                    continue\n",
    "                idx = len(answer_dict)\n",
    "                unique_answers.append(answer)\n",
    "                answer_dict[answer] = idx\n",
    "            print(f'[fold: {fold}][{name}] size of unique answers:',\n",
    "                  len(unique_answers))\n",
    "            for idx, answer in enumerate(unique_answers):\n",
    "                f.write(f'{idx}\\t-\\t{answer}\\n')\n",
    "            # 问题\n",
    "            question_dict = {}\n",
    "            unique_questions = []\n",
    "            with open(os.path.join(fold_output_dir, f'{name}_query.txt'),\n",
    "                      'w') as f:\n",
    "                for q in data['questions']:\n",
    "                    if q in question_dict:\n",
    "                        continue\n",
    "                    idx = len(question_dict)\n",
    "                    unique_questions.append(q)\n",
    "                    question_dict[q] = idx\n",
    "                print(f'[fold: {fold}][{name}] size of unique questions:',\n",
    "                      len(unique_questions))\n",
    "                for idx, q in enumerate(unique_questions):\n",
    "                    f.write(f'{idx}\\t{q}\\n')\n",
    "            # rels 里的格式是一行一对，一对多的分多行，参考msmacro dev里的 178627\n",
    "            with open(os.path.join(fold_output_dir, f'qrels_{name}.tsv'),\n",
    "                      'w') as f:\n",
    "                for q, a in zip(data['questions'], data['answers']):\n",
    "                    q_id = question_dict[q]\n",
    "                    a_id = answer_dict[a]\n",
    "                    f.write(f'{q_id}\\t{a_id}\\n')\n",
    "                print(f'[fold: {fold}][{name}] size of q-a pairs:',\n",
    "                      len(data['questions']))\n",
    "    fold = fold + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 接下来处理测试集，注意变量跟上面是重名的，为了方便"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['questions', 'candidates', 'ground_truths'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(reqa_test_json) as f:\n",
    "    data=json.load(f)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data:\n",
    "    for i in range(len(data[key])):\n",
    "        if isinstance(data[key][i],str):\n",
    "            data[key][i]=data[key][i].replace('\\r','').replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of unique answers: 31682\n"
     ]
    }
   ],
   "source": [
    "answer_dict={}\n",
    "unique_answers=[]\n",
    "with open(os.path.join(output_dir,'test_corpus.tsv'),'w') as f:\n",
    "    for answer in data['candidates']:\n",
    "        if answer in answer_dict:\n",
    "            continue\n",
    "        idx=len(answer_dict)\n",
    "        unique_answers.append(answer)\n",
    "        answer_dict[answer]=idx\n",
    "    print('size of unique answers:',len(unique_answers))\n",
    "    for idx,answer in enumerate(unique_answers):\n",
    "        f.write(f'{idx}\\t-\\t{answer}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of unique questions: 496\n"
     ]
    }
   ],
   "source": [
    "question_dict={}\n",
    "unique_questions=[]\n",
    "with open(os.path.join(output_dir,'test_query.txt'),'w') as f:\n",
    "    for q in data['questions']:\n",
    "        if q in question_dict:\n",
    "            continue\n",
    "        idx=len(question_dict)\n",
    "        unique_questions.append(q)\n",
    "        question_dict[q]=idx\n",
    "    print('size of unique questions:',len(unique_questions))\n",
    "    for idx,q in enumerate(unique_questions):\n",
    "        f.write(f'{idx}\\t{q}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of q-a pairs: 1467\n",
      "size of used answers: 1466\n"
     ]
    }
   ],
   "source": [
    "# rels 里的格式是一行一对，一对多的分多行，参考msmacro dev里的 178627\n",
    "used_answers=[]\n",
    "with open(os.path.join(output_dir,'qrels_test.tsv'),'w') as f:\n",
    "    cnt=0\n",
    "    for q,ground_truths in zip(data['questions'],data['ground_truths']):\n",
    "        for c_id in ground_truths:\n",
    "            a=data['candidates'][c_id]\n",
    "            used_answers.append(c_id)\n",
    "            q_id=question_dict[q]\n",
    "            a_id=answer_dict[a]\n",
    "            f.write(f'{q_id}\\t{a_id}\\n')\n",
    "            cnt+=1\n",
    "    print('size of q-a pairs:',cnt)\n",
    "    print('size of used answers:',len(set(used_answers)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a872c9041ce0299b31a57e4b0373f87f3e846c1dede026ee1a0de5432b23cbb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
